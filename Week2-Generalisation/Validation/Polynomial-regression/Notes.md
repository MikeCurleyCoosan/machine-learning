
# Generalisation is the goal of ML

*Want good performance for new data
*How good the generalisation, is how well it performs on previously â€œunseen dataâ€ i.e. data not
used to train the set.

## Definition:

â–ª Generalisation is the modelâ€™s ability to give sensible outputs to sets of input that it has never seen before

â–ª Root-mean-squared (RMS) error could be used to measure: ğ¸ğ‘…ğ‘€ğ‘† = $$\sqrt{2ğ¸(ğ‘¤ âˆ—)/ğ‘}$$

â–ª Back to previous idea of checking how far away pred is away from the original y, what is
the problem?

â–ª We are checking the Generalisation of the model by using data it was trained on - i.e. it
is NOT previously unseen.

â–ª Our model may be overfit to the training data.

##
â–ª The opposite problem is under-fitting.
â–ª You canâ€™t even seem to reduce your training loss to anything reasonable. This is like  